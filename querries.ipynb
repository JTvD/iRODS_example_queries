{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A few example Irods querries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import platform\n",
    "import subprocess\n",
    "from getpass import getpass\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from irods.collection import Collection\n",
    "from irods.data_object import DataObject\n",
    "from irods.column import Criterion\n",
    "from irods.models import Resource, DataObjectMeta\n",
    "\n",
    "from ibridges import Session\n",
    "from ibridges.meta import MetaData\n",
    "from ibridges.util import get_dataobject\n",
    "from ibridges.path import IrodsPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a session\n",
    "Depending on the IDE the prompt to enter the password might appear on the top or bottom of the screen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_file = Path(\"~\").expanduser().joinpath(\".irods\", 'irods_environment.json')\n",
    "password = getpass('Your iRODS password')\n",
    "session = Session(irods_env=env_file, password=password)\n",
    "session\n",
    "# Check user type\n",
    "user_type, user_groups = session.get_user_info()\n",
    "if 'rodsadmin' in user_type:\n",
    "    print(\"You are a rodsadmin\")\n",
    "\n",
    "# Check if iccomands are available\n",
    "icomm = False\n",
    "is_linux = 'linux' in platform.platform().lower()\n",
    "if is_linux:\n",
    "    # Do not use check_output().  It raises an exception.\n",
    "    if subprocess.call(['which', 'iinit']) == 0:\n",
    "        print(\"icommands found on Linux\")\n",
    "        icomm = True\n",
    "elif subprocess.call(['where', 'iinit']) == 0:\n",
    "        print(\"icommands found on Windows\")\n",
    "        icomm = True\n",
    "else:\n",
    "    print(\"icommands not found\")\n",
    "\n",
    "# Check if the default environment json is loaded. \n",
    "if env_file.name == 'irods_environment.json' and icomm and 'rodsadmin' in user_type:\n",
    "    subprocess.call(['iinit', password])\n",
    "    print(\"all set, icommands activated\")\n",
    "else:\n",
    "    icomm = False\n",
    "    print(\"icommands automatically loads the default environment file: irods_environment.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data objects status\n",
    "All data objects have a status between 0 and 4 which can be used to detect problems: \n",
    "- '0': 'stale'\n",
    "- '1': 'good'\n",
    "- '2': 'intermediate'\n",
    "- '3': 'read-locked'\n",
    "- '4': 'write-locked'\n",
    "Only the status of '1' indicates the file is correctly uploaded.\n",
    "\n",
    "The querry of the PRC can querry the status and list all files that are not 'good', but it cannot fix them.\n",
    "For that the icommands, the python function creates the icommand lines which can directly be executed in the commandline if the icommands are installed. (and iinit has been run on the same server!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofmodrepl = []\n",
    "dict_list = []\n",
    "query = session.irods_session.query(Collection.name, DataObject.name, DataObject.replica_number).filter(Criterion('<>',DataObject.replica_status,'1'))\n",
    "for result in query:\n",
    "    dict_list.append({\"Collection\": result[Collection.name], \n",
    "                      \"DataObject\": result[DataObject.name], \n",
    "                      \"ReplicaNumber\": result[DataObject.replica_number]})\n",
    "    #print(\"f\"{result[Collection.name]}/{result[DataObject.name]} {result[DataObject.replica_number]}\")\n",
    "files_df = pd.DataFrame(dict_list)\n",
    "files_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For RODSadmins: create the modrepl commands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in query:\n",
    "    command = 'iadmin modrepl logical_path {}/{} replica_number {} DATA_REPL_STATUS 1'.format(result[Collection.name],result[DataObject.name],result[DataObject.replica_number])\n",
    "    listofmodrepl.append(command)\n",
    "\n",
    "for item in listofmodrepl:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If icommands are initialized execute the commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in listofmodrepl:\n",
    "    result = subprocess.call(item, shell=True, capture_output=True)\n",
    "    if result.returncode != 0:\n",
    "        print(\"Error executing command: \", result.stderr)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage insight?\n",
    "Data is moved around a lot, it starts on a 'hot' storage and is later moved to a 'medium' or 'cold' resoruce like a tape archive.  \n",
    "However, over time data is also retreived, moved backed. Potentially even updated.   \n",
    "During this process it is quite easy to forget a file somewhere. And before you know it the resource is full...  \n",
    "Luckily, even users can list the resources they have acces to and list the freespace and files on them:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the resrouce names and the free space\n",
    "for resc in session.irods_session.query(Resource.name, Resource.free_space).get_results():\n",
    "    print(f\"{resc[Resource.name]}: \\t {resc[Resource.free_space]} \\t {Resource.children}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querry all files on a specific resource and return them as a pandas dataframe for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all data on a specific resource\n",
    "hot_resc = 'hot_1'\n",
    "query = session.irods_session.query(Collection.name, DataObject).filter(DataObject.resource_name == hot_resc).get_results()\n",
    "total_size = 0\n",
    "dict_list = []\n",
    "for result in query:\n",
    "    dict_list.append({\"Collection\": result[Collection.name], \n",
    "                      \"DataObject\": result[DataObject.name], \n",
    "                      \"size\": result[DataObject.size], \n",
    "                      \"checksum\": result[DataObject.checksum]})\n",
    "    # print(f\"{result[Collection.name]} {result[DataObject.name]} {result[DataObject.checksum]}\")\n",
    "    total_size += result[DataObject.size]\n",
    "\n",
    "files_df = pd.DataFrame(dict_list)\n",
    "print(f\"Total number of files: {len(result)} with a size of {total_size} bytes\")\n",
    "print(files_df).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List only the files in a specific collection on a specific resource\n",
    "The Querries can be extended with filters to get most detailed results.  \n",
    "As an example this is a filter on the collection name. Below there are also filters on metadata\n",
    "Note these two filters give the same result:  \n",
    "- 'filter(DataObject.replica_status != 1)'  \n",
    "- 'filter(Criterion('<>',DataObject.replica_status,'1'))'   \n",
    "\n",
    "The Criterion gives more freedom to add specific keywords as: 'like', 'not like', '='. The wildcard is '%' for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_resc = 'hot_1'\n",
    "collection_name_filter = Criterion('like', Collection.name , '/NPEC/%')\n",
    "query = session.irods_session.query(Collection.name, DataObject).filter(DataObject.resource_name == hot_resc).filter(collection_name_filter).get_results()\n",
    "total_size = 0\n",
    "for result in query:\n",
    "    print(f\"{result[Collection.name]} {result[DataObject.name]} {result[DataObject.checksum]}\")\n",
    "    total_size += result[DataObject.size]\n",
    "\n",
    "print(f\"Total number of files: {len(result)} with a size of {total_size} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing only the files retreived from archive\n",
    "This is an advanced querry which depends on the spectific setup, the instance I used duplication on the irods level for the tape archive and on the storage level for the 'hot' resources.  \n",
    "As a result there are two replica's on tape visible in iRODS and one on hot.   \n",
    "\n",
    "When data is move to tape, replica 1 & 2 become the tape archives. If a file is now retreived this becomes replica number 3. \n",
    "By adding an aditional filter on the name of the hot resource the user is 100% sure these are the files that have been retreived from tape.  \n",
    "Giving an overview that can be used to keepup the old retreived data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_resc = 'hot_1'\n",
    "replica_number = 3\n",
    "query = session.irods_session.query(Collection.name, DataObject).filter(DataObject.replica_number==replica_number).filter(DataObject.resource_name == hot_resc).get_results()\n",
    "dict_list = []\n",
    "for result in query:\n",
    "    dict_list.append({\"Collection\": result[Collection.name], \n",
    "                    \"DataObject\": result[DataObject.name], \n",
    "                    \"size\": result[DataObject.size], \n",
    "                    \"checksum\": result[DataObject.checksum]})\n",
    "    # print(f\"{result[Collection.name]} {result[DataObject.name]} {result[DataObject.checksum]}\")\n",
    "files_df = pd.DataFrame(dict_list)\n",
    "files_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using querries to search through the metadata\n",
    "Metadata is added in key, value, unit triples.\n",
    "On way to search through these is to filter the returns of a querry\n",
    "- 'DataObjectMeta.name' is the key\n",
    "- 'DataObjectMeta.value' is the value\n",
    "- 'DataObjectMeta.units' is the unit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = session.irods_session.query(Collection.name, DataObject, case_sensitive = False).filter(DataObjectMeta.name == 'Crop').filter(DataObjectMeta.value == 'Potato').get_results()\n",
    "dict_list = []\n",
    "for result in query:\n",
    "    dict_list.append({\"Collection\": result[Collection.name], \n",
    "                \"DataObject\": result[DataObject.name], \n",
    "                \"size\": result[DataObject.size], \n",
    "                \"checksum\": result[DataObject.checksum]})\n",
    "    #print(f\"{result[Collection.name]} {result[DataObject.name]} {result[DataObject.checksum]}\")\n",
    "files_df = pd.DataFrame(dict_list)\n",
    "files_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List the metadata of a specific object  \n",
    "First get the data object, than access it's metadata.  \n",
    "Additionally new values can be added with: 'obj_meta.add('Test', None, None)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataobject_path = '/NPEC/home/path to dataobject'\n",
    "i_path = IrodsPath(session, dataobject_path)\n",
    "do = get_dataobject(session, i_path)\n",
    "obj_meta = MetaData(do)\n",
    "metadata = obj_meta.to_dict()['metadata']\n",
    "for key, val, unit in metadata:\n",
    "    print(f\"{key} {val} {unit}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
